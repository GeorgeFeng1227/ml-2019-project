{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data\n",
    "Reading files that contain the biased (WikiDetox) and unbiased (50/50 aggressive/unaggressive) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbias score data inputed\n",
      "comment_data & target_unbias\n"
     ]
    }
   ],
   "source": [
    "#unbiased data input\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as nd\n",
    "import re\n",
    "\n",
    "Number_of_entry = 29560 #maximum acceptable 29560\n",
    "#input data and clean up\n",
    "agg_data = pd.read_csv('Aggressive_scored.tsv', sep = '\\t', nrows = Number_of_entry/2)\n",
    "neu_data = pd.read_csv('Friendlier_scored.tsv', sep = '\\t', nrows = Number_of_entry/2)\n",
    "\n",
    "agg_comment = agg_data.comment\n",
    "neu_comment = neu_data.comment\n",
    "agg_target = agg_data.aggression_score\n",
    "neu_target = neu_data.aggression_score\n",
    "\n",
    "comment_data = np.asarray(agg_comment.append(neu_comment))\n",
    "target_unbias = np.asarray(agg_target.append(neu_target))\n",
    "print(\"unbias score data inputed\")\n",
    "print(\"comment_data & target_unbias\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Removes punctuation, newlinetoken, stop words for unbiased and biased data, lemmatizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step of preprocessing\n",
    "PUNCTUATION_NO_SPACE = re.compile(\"[.;:!*=<>`_'?Â¿,\\\"()\\[\\]]\")\n",
    "PUNCTUATION_SPACE = re.compile(\"-\")\n",
    "NEWLINE = re.compile(\"newlinetoken\")\n",
    "#This is more or less the nltk stop list with negations removed\n",
    "skip = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", 'im',\"youre\",\n",
    "        \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', \n",
    "        'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', \n",
    "        'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \n",
    "        \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', \n",
    "        'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'if', 'or', 'ive',\n",
    "        'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between', \n",
    "        'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', \n",
    "        'out', 'on', 'off', 'over', 'under', 'further', 'then', 'once', 'here', 'there', 'theres','when', 'where',\n",
    "        'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such',\n",
    "        'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', \n",
    "        'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y','u','ur']\n",
    "\n",
    "#unbiased\n",
    "for i in range(comment_data.size):\n",
    "    comment_data[i] = PUNCTUATION_NO_SPACE.sub(\"\",comment_data[i].lower())\n",
    "    comment_data[i] = NEWLINE.sub(\"\",comment_data[i])\n",
    "    comment_data[i] = PUNCTUATION_SPACE.sub(\" \",comment_data[i].lower())\n",
    "    comment_data[i] = comment_data[i].split()\n",
    "    comment_data[i] = [word for word in comment_data[i] if word not in skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Kiara2.0/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Removing different ending of the same word\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "for i in range(comment_data.size):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    comment_data[i] = ' '.join([lemmatizer.lemmatize(word) for word in comment_data[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(target_unbias.size):\n",
    "    if (target_unbias[i] > 3.5):\n",
    "        target_unbias[i] = 4\n",
    "    elif (target_unbias[i] > 2.5):\n",
    "        target_unbias[i] = 3\n",
    "    elif (target_unbias[i] > 1.5):\n",
    "        target_unbias[i] = 2\n",
    "    elif (target_unbias[i] > 0.5):\n",
    "        target_unbias[i] = 1\n",
    "    else:\n",
    "        target_unbias[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for binary prediction\n",
    "Uses the TfidfVectorizer and LinearSVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbias data Accuracy:  0.7587753721244925\n"
     ]
    }
   ],
   "source": [
    "#model for binary predicting\n",
    "#default TF-idf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "comment_data = np.asarray(comment_data)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,5),analyzer='char_wb')\n",
    "tfidf_vectorizer.fit(comment_data)\n",
    "comment_vectorized = tfidf_vectorizer.transform(comment_data)\n",
    "    \n",
    "def accuracy_test(ind, c=1, trials=50):\n",
    "    total = 0\n",
    "    #print(comment_vectorized.shape)\n",
    "    model = None\n",
    "    for i in range(trials):\n",
    "        data_train, data_test, target_train, target_test = train_test_split(\n",
    "            comment_vectorized, target_unbias, test_size = 0.1)\n",
    "\n",
    "        model = LogisticRegression(C=c)\n",
    "        model.fit(data_train, target_train)\n",
    "        total += accuracy_score(target_test, model.predict(data_test))\n",
    "    accuracy = total / trials\n",
    "    print(\"Unbias data Accuracy: \", accuracy)\n",
    "    return model\n",
    "\n",
    "model_ub = accuracy_test(ind = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Interaction\n",
    "Uses LinearSVC model with Ngram = 1 to predict user input live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write your comment here, or type 'exit': thanks, good catch\n",
      "---Your input comment is classified as friendly!---\n",
      "\n",
      "Write your comment here, or type 'exit': you clearly have no idea what you're doing\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': air canada in exclusive talks to purchase air transat\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': are you stupid or just ignorant?\n",
      "---Your input comment is classified as aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': ill put you in a body bag\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': I'll send you to the grave.\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': I'll push you off a cliff\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': Go fall off a cliff\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': Go fall and die\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': Go die\n",
      "---Your input comment is classified as very aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': DIe\n",
      "---Your input comment is classified as very aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': Melt in your mouth sounds good\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': Go melt in your mouth\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': il;\\\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': Attack me\n",
      "---Your input comment is classified as aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': Fuck me\n",
      "---Your input comment is classified as very aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': frick you\n",
      "---Your input comment is classified as very aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': arse\n",
      "---Your input comment is classified as aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': tu es una puta\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': pendejo\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': cuck\n",
      "---Your input comment is classified as very aggressive!---\n",
      "\n",
      "Write your comment here, or type 'exit': beta\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': soyboy\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': incel\n",
      "---Your input comment is classified as neutral!---\n",
      "\n",
      "Write your comment here, or type 'exit': republicans\n",
      "---Your input comment is classified as neutral!---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicting user input\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 5),analyzer='char_wb')\n",
    "tfidf_vectorizer.fit(comment_data)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Write your comment here, or type 'exit': \")\n",
    "    if user_input == 'exit' :\n",
    "        break\n",
    "\n",
    "    user_input = PUNCTUATION_NO_SPACE.sub(\"\",user_input.lower())\n",
    "    user_input = NEWLINE.sub(\"\",user_input)\n",
    "    user_input = PUNCTUATION_SPACE.sub(\" \",user_input.lower())\n",
    "    user_input = user_input.split()\n",
    "    user_input = [word for word in user_input if word not in skip]\n",
    "  \n",
    "    comment_data[i] = ' '.join([lemmatizer.lemmatize(word) for word in user_input])\n",
    "    \n",
    "    user_input_vec = tfidf_vectorizer.transform(user_input)\n",
    "\n",
    "    predicted_result = model_ub.predict(user_input_vec)\n",
    "\n",
    "    if (np.mean(predicted_result > 3.5)):\n",
    "        print(\"---Your input comment is classified as very friendly!---\\n\")\n",
    "    elif (np.mean(predicted_result > 2.5)):\n",
    "        print(\"---Your input comment is classified as friendly!---\\n\")\n",
    "    elif (np.mean(predicted_result > 1.5)):\n",
    "        print(\"---Your input comment is classified as neutral!---\\n\")\n",
    "    elif (np.mean(predicted_result > 0.5)):\n",
    "        print(\"---Your input comment is classified as aggressive!---\\n\")\n",
    "    else:\n",
    "        print(\"---Your input comment is classified as very aggressive!---\\n\")\n",
    "print(\"Exited program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
